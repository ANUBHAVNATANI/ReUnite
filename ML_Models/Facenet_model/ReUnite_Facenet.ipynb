{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code published under 24 hour hackathon<br>\n",
    "Author : **Pawan Jain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import pickle\n",
    "import cv2\n",
    "import os.path\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt #data to string and than string to datatype\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utility import *\n",
    "from webcam_utility import *\n",
    "np.set_printoptions(threshold=np.nan) #determine way floating point numbers, arrays are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The model makes an encoding vector consisting of 128 numbers for the input image. Two encodings are compared and if the two encodings are similar then we say that the two images are of the same person otherwise they are different. \n",
    "The model uses **Triplet loss function**. The aim is to minimize this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # triplet formula components\n",
    "    pos_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[1])) )\n",
    "    neg_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[2])) )\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    loss = tf.maximum(basic_loss, 0.0)\n",
    "   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model\n",
    "The model outputs a vector of 128 numbers which represent encoding for the given input image. We will be using this encoding vector for comparing two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "FRmodel = load_model('models/model.h5', custom_objects={'triplet_loss': triplet_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(database, model):\n",
    "    save_loc = r'saved_image/1.jpg' \n",
    "    capture_obj = cv2.VideoCapture(0)\n",
    "    capture_obj.set(3, 640)  # WIDTH\n",
    "    capture_obj.set(4, 480)  # HEIGHT\n",
    "\n",
    "    #classifier to detect object\n",
    "    face_cascade = cv2.CascadeClassifier(r'haarcascades/haarcascade_frontalface_default.xml') \n",
    "    \n",
    "    # whether there was any face found or not\n",
    "    face_found = False\n",
    "\n",
    "    # run the webcam for given seconds\n",
    "    req_sec = 3\n",
    "    loop_start = time.time()\n",
    "    elapsed = 0\n",
    "\n",
    "    while(True):\n",
    "        curr_time = time.time()\n",
    "        elapsed = curr_time - loop_start\n",
    "        if elapsed >= req_sec:\n",
    "            break\n",
    "\n",
    "        # capture_object frame-by-frame\n",
    "        ret, frame = capture_obj.read()\n",
    "        # mirror the frame\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "\n",
    "        # Our operations on the frame come here\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # detect face\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        for (x, y, w, h) in faces:\n",
    "            # required region for the face\n",
    "            roi_color = frame[y-90:y+h+70, x-50:x+w+50]\n",
    "            # save the detected face\n",
    "            cv2.imwrite(save_loc, roi_color)\n",
    "            # draw a rectangle bounding the face\n",
    "            cv2.rectangle(frame, (x-10, y-70),(x+w+20, y+h+40), (15, 175, 61), 4)\n",
    "            \n",
    "        # display the frame with bounding rectangle\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # close the webcam when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the capture_object\n",
    "    capture_obj.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    img = cv2.imread(save_loc)\n",
    "    if img is not None:\n",
    "        face_found = True\n",
    "    else:\n",
    "        face_found = False\n",
    "\n",
    "    return face_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_realtime(database, model, threshold=0.7):\n",
    "    text = ''\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    save_loc = r'saved_image/1.jpg'\n",
    "    capture_obj = cv2.VideoCapture(0)\n",
    "    capture_obj.set(3, 640)  # WIDTH\n",
    "    capture_obj.set(4, 480)  # HEIGHT\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    print('**************** Enter \"q\" to quit **********************')\n",
    "    prev_time = time.time()\n",
    "    while(True):\n",
    "\n",
    "        # capture_object frame-by-frame\n",
    "        ret, frame = capture_obj.read()\n",
    "        # mirror the frame\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "\n",
    "        # Our operations on the frame come here\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # detect face\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        for (x, y, w, h) in faces:\n",
    "            # required region for the face\n",
    "            roi_color = frame[y-90:y+h+70, x-50:x+w+50]\n",
    "\n",
    "            # save the detected face\n",
    "            cv2.imwrite(save_loc, roi_color)\n",
    "\n",
    "            # keeps track of waiting time for face recognition\n",
    "            curr_time = time.time()\n",
    "\n",
    "            if curr_time - prev_time >= 3:\n",
    "                img = cv2.imread(save_loc)\n",
    "                if img is not None:\n",
    "                    resize_img(save_loc)\n",
    "\n",
    "                    min_dist, identity, registered = find_face_realtime(\n",
    "                        save_loc, database, model, threshold)\n",
    "\n",
    "                    if min_dist <= threshold and registered:\n",
    "                        # for putting text overlay on webcam feed\n",
    "                        text = 'You Found' + identity\n",
    "                        print('You Fount ' + identity + '!')\n",
    "                    else:\n",
    "                        text = 'Unknown user'\n",
    "                        print('Unknown user' + ' detected !')\n",
    "                    print('distance:' + str(min_dist))\n",
    "                # save the time when the last face recognition task was done\n",
    "                prev_time = time.time()\n",
    "\n",
    "            # draw a rectangle bounding the face\n",
    "            cv2.rectangle(frame, (x-10, y-70),\n",
    "                          (x+w+20, y+h+40), (15, 175, 61), 4)\n",
    "            cv2.putText(frame, text, (50, 50), font, 1.8, (158, 11, 40), 3)\n",
    "\n",
    "        # display the frame with bounding rectangle\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # close the webcam when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # release the capture_object\n",
    "    capture_obj.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks whether the input face is a registered user or not\n",
    "def find_face_realtime(image_path, database, model, threshold):\n",
    "    # find the face encodings for the input image\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    registered = False\n",
    "    min_dist = 99999\n",
    "    identity = 'Unknown Person'\n",
    "    # loop over all the recorded encodings in database\n",
    "    for name in database:\n",
    "        # find the similarity between the input encodings and claimed person's encodings using L2 norm\n",
    "        dist = np.linalg.norm(np.subtract(database[name], encoding))\n",
    "        # check if minimum distance or not\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > threshold:\n",
    "        registered = False\n",
    "    else:\n",
    "        registered = True\n",
    "    return min_dist, identity, registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads and resizes an image\n",
    "def resize_img(image_path):\n",
    "    img = cv2.imread(image_path, 1)\n",
    "    img = cv2.resize(img, (96, 96))\n",
    "    cv2.imwrite(image_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add or delete user \n",
    "\n",
    "We will create a database of registered. For this we will use a simple dictionary and map each registered user with his/her face encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a dict for keeping track of ampping of each person with his/her face encoding\n",
    "user_db = ini_user_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the user database\n",
    "def ini_user_database():\n",
    "    # check for existing database\n",
    "    if os.path.exists('database/user_dict.pickle'):\n",
    "        with open('database/user_dict.pickle', 'rb') as handle:\n",
    "            user_db = pickle.load(handle)   \n",
    "    else:\n",
    "        # make a new one\n",
    "        # we use a dict for keeping track of mapping of each person with his/her face encoding\n",
    "        user_db = {}\n",
    "     \n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds a new user face to the database using his/her image stored on disk using the image path\n",
    "def add_user_img_path(user_db, FRmodel, name, img_path):\n",
    "    if name not in user_db: \n",
    "        user_db[name] = img_to_encoding(img_path, FRmodel)\n",
    "        # save the database\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "                pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('User ' + name + ' added successfully')\n",
    "    else:\n",
    "        print('The name is already registered! Try a different name.........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes a registered user from database\n",
    "def delete_user(user_db, name):\n",
    "    popped = user_db.pop(name, None)\n",
    "    \n",
    "    if popped is not None:\n",
    "        print('User ' + name + ' deleted successfully')\n",
    "        # save the database\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "                pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    elif popped == None:\n",
    "        print('No such user !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "For making this face recognition system we are going to take the input image, find its encoding and then see if there is any similar encoding in the database or not. We define a threshold value to decide whether the two images are similar or not based on the similarity of their encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize the input user face encoding by checking for it in the database\n",
    "def find_face(image_path, database, model, threshold = 0.6):\n",
    "    # find the face encodings for the input image\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    \n",
    "    min_dist = 99999\n",
    "    # loop over all the recorded encodings in database \n",
    "    for name in database:\n",
    "        # find the similarity between the input encodings and claimed person's encodings using L2 norm\n",
    "        dist = np.linalg.norm(np.subtract(database[name], encoding) )\n",
    "        # check if minimum distance or not\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > threshold:\n",
    "        print(\"User not in the database.\")\n",
    "        identity = 'Unknown Person'\n",
    "    else:\n",
    "        print (\"Hi! \" + str(identity) + \", L2 distance: \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# takes an input image and performs face recognition on it\n",
    "def do_face_recognition(user_db, FRmodel, threshold, save_loc):\n",
    "    # we can use the webcam to capture the user image then get it recognized\n",
    "    face_found = detect_face(user_db, FRmodel)\n",
    "\n",
    "    if face_found:\n",
    "        resize_img(save_loc)\n",
    "        find_face(save_loc, user_db, FRmodel, threshold)\n",
    "    else:\n",
    "        print('There was no face found in the visible frame. Try again...........')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add image via path** : add_user_img_path(user_db, FRmodel, \"Pj\", \"saved_image/1.jpg\") <br>\n",
    "**To delete user data** : delete_user(user_db, \"Pawan\")<br>\n",
    "**To recognise face** : do_face_recognition(user_db, FRmodel, 0.6, \"image location : saved_image/1.jpg\")<br>\n",
    "**To detect face** : detect_face_realtime(user_db, FRmodel, threshold = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "root = Tk()\n",
    "\n",
    "topFrame = Frame(root)\n",
    "topFrame.pack()\n",
    "bottomFrame = Frame(root)\n",
    "bottomFrame.pack(side=BOTTOM)\n",
    "\n",
    "button1 = Button(topFrame, text=\"Recognise\", command = lambda:do_face_recognition(user_db, FRmodel, 0.6, \"saved_image/1.jpg\"))\n",
    "button2 = Button(topFrame, text=\"Detect\", command= lambda:detect_face_realtime(user_db, FRmodel, threshold = 0.7))\n",
    "button3 = Button(topFrame, text=\"Add new missing\", command=lambda:add_user_img_path(user_db, FRmodel, \"Pj\", \"saved_image/1.jpg\") )\n",
    "\n",
    "button1.pack(padx=5, pady=10,side=BOTTOM)\n",
    "button2.pack(padx=5, pady=10,side=BOTTOM)\n",
    "button3.pack(padx=5, pady=10,side=BOTTOM)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Work\n",
    "<ul><li> Add some more convenient method to input image data\n",
    "    <li> Form for user data in tkinter gui\n",
    "    <li> Add graphs of loss, cross entropy etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Convolutional Neural Networks Specialization by Deeplearning.ai on Coursera.\n",
    "https://www.coursera.org/learn/convolutional-neural-networks/home/welcome \n",
    "- Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "- The pretrained model used is inspired by Victor Sy Wang's implementation and was loaded using his code: https://github.com/iwantooxxoox/Keras-OpenFace.\n",
    "- A lot of explanation from http://llcao.net/cu-deeplearning17/pp/class10_FaceNet.pdf by Florian Schroff, Dmitry Kalenichenko, James Philbin"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "IaknP",
   "launcher_item_id": "5UMr4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
